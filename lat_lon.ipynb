{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.11/site-packages (4.22.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (2024.6.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: websocket-client>=1.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###website\n",
    "\n",
    "http://www.geocountries.com/country/geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (126.0.6478.126) detected in PATH at /opt/homebrew/bin/chromedriver might not be compatible with the detected chrome version (127.0.6533.120); currently, chromedriver 127.0.6533.119 is recommended for chrome 127.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping complete. Data saved to 'country_lat_lon.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the website to scrape\n",
    "url = 'http://www.geocountries.com/country/geolocation'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait until the table element is present\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    ")\n",
    "\n",
    "# Get the page source after it has been fully rendered\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Find the table that contains the country, latitude, and longitude data\n",
    "table = soup.find('table')\n",
    "\n",
    "# Create lists to hold the scraped data\n",
    "countries = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "# Loop through the table rows and extract the country, latitude, and longitude data\n",
    "for row in table.find_all('tr'):\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    # Ensure that the row has exactly three columns\n",
    "    if len(columns) == 3:\n",
    "        country = columns[0].text.strip()\n",
    "        latitude = columns[1].text.strip()\n",
    "        longitude = columns[2].text.strip()\n",
    "        \n",
    "        countries.append(country)\n",
    "        latitudes.append(latitude)\n",
    "        longitudes.append(longitude)\n",
    "\n",
    "# Create a DataFrame to organize the data\n",
    "data = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Latitude': latitudes,\n",
    "    'Longitude': longitudes\n",
    "})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "data.to_csv('country_lat_lon.csv', index=False)\n",
    "\n",
    "print(\"Data scraping complete. Data saved to 'country_lat_lon.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
